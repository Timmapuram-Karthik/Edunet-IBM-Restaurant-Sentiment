{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Restaurant Reviews\n",
    "\n",
    "### This script performs sentiment analysis on a collection of restaurant reviews using machine learning techniques. Sentiment analysis aims to determine the sentiment expressed in text, specifically whether a review conveys a positive or negative sentiment about a restaurant experience.\n",
    "\n",
    "### Steps:\n",
    "1. Data Loading and Exploration: The script loads a dataset containing restaurant reviews from a TSV file.It checks for any missing values and provides a glimpse of the dataset's structure.\n",
    "\n",
    "2. Data Preprocessing: The text data in the reviews undergoes preprocessing to ensure consistency and remove irrelevant information. The text is converted to lowercase, tokenized into words, and stemmed to their root forms. Common stopwords are also removed to focus on meaningful content.\n",
    "\n",
    "3. Feature Extraction: To enable machine learning models to process text data, the preprocessed reviews are transformed into numerical features. This process, known as Count vectorization, assigns weights to words based on their importance within each review and across the entire dataset.\n",
    "\n",
    "4. Model Selection and Evaluation: The script considers multiple machine learning models for sentiment analysis, including Multinomial Naive Bayes, Random Forest, Gradient Boosting, XG Boost and Support Vector Classifier (SVC).Each model is trained on a subset of the data and evaluated on another subset to measure its predictive ability.\n",
    "\n",
    "5. Best Model Identification: During evaluation, the script identifies the best-performing model based on its accuracy in predicting sentiment. This helps determine which model is most effective for this analysis.\n",
    "\n",
    "6. Evaluation Metrics and Insights: The script provides evaluation metrics such as accuracy, which reflects the proportion of correctly predicted sentiments. Additionally, it generates a confusion matrix and a classification report to offer insights into model performance for positive and negative sentiments.\n",
    "\n",
    "7. Conclusion: Sentiment analysis of restaurant reviews holds practical value for understanding customer opinions, improving restaurant services, and making informed business decisions. This script demonstrates the process of preprocessing text, training machine learning models, and evaluating their performance in sentiment analysis.\n",
    "\n",
    "### Sentiment analysis plays a crucial role in extracting valuable insights from unstructured text data, contributing to enhanced customer experiences and data-driven decision-making in the restaurant industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n",
    "from spacy.lang.en import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "review=pd.read_csv(\"https://raw.githubusercontent.com/Timmapuram-Karthik/Edunet-IBM-Restaurant-Sentiment/main/Restaurant_Reviews.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for any missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    0\n",
       "Liked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the last few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "stopwords=list(STOP_WORDS)\n",
    "stopwords_to_remove=[\"nâ€˜t\",\"n't\",\"nâ€™t\",\"not\"]\n",
    "stopwords=[word for word in stopwords if word not in stopwords_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(review.shape[0]):\n",
    "    data=review.iloc[i,0]\n",
    "    data=data.lower()\n",
    "    data=data.split()\n",
    "    ps=PorterStemmer()\n",
    "    data=[ps.stem(word) for word in data if not word in set(stopwords)]\n",
    "    data=' '.join(data)\n",
    "    corpus.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Count vectorizer and transform the text data into a numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(max_features=1500, ngram_range=(1, 2), stop_words='english')\n",
    "x=cv.fit_transform(corpus).toarray()\n",
    "y=review['Liked'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes models for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 0.91875\n",
      "Test Accuracy = 0.77\n"
     ]
    }
   ],
   "source": [
    "MultinomialNB=MultinomialNB()\n",
    "MultinomialNB.fit(x_train,y_train)\n",
    "train_score=MultinomialNB.score(x_train,y_train)\n",
    "test_score=MultinomialNB.score(x_test,y_test)\n",
    "print(f\"Train Accuracy = {train_score}\\nTest Accuracy = {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[77 26]\n",
      " [20 77]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=MultinomialNB.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77       103\n",
      "           1       0.75      0.79      0.77        97\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.77      0.77      0.77       200\n",
      "weighted avg       0.77      0.77      0.77       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest models for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 0.7925\n",
      "Test Accuracy = 0.725\n"
     ]
    }
   ],
   "source": [
    "RandomForestClassifier=RandomForestClassifier(n_estimators=100,max_depth=4)\n",
    "RandomForestClassifier.fit(x_train,y_train)\n",
    "train_score=RandomForestClassifier.score(x_train,y_train)\n",
    "test_score=RandomForestClassifier.score(x_test,y_test)\n",
    "print(f\"Train Accuracy = {train_score}\\nTest Accuracy = {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[94  9]\n",
      " [46 51]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=RandomForestClassifier.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.91      0.77       103\n",
      "           1       0.85      0.53      0.65        97\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.76      0.72      0.71       200\n",
      "weighted avg       0.76      0.72      0.71       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting models for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 0.81875\n",
      "Test Accuracy = 0.8\n"
     ]
    }
   ],
   "source": [
    "GradientBoostingClassifier=GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "GradientBoostingClassifier.fit(x_train,y_train)\n",
    "train_score=GradientBoostingClassifier.score(x_train,y_train)\n",
    "test_score=GradientBoostingClassifier.score(x_test,y_test)\n",
    "print(f\"Train Accuracy = {train_score}\\nTest Accuracy = {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[99  4]\n",
      " [36 61]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=GradientBoostingClassifier.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83       103\n",
      "           1       0.94      0.63      0.75        97\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.84      0.80      0.79       200\n",
      "weighted avg       0.83      0.80      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XG Boost models for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 0.74875\n",
      "Test Accuracy = 0.745\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = XGBClassifier(n_estimators=100,learning_rate=0.1,max_depth=3,random_state=42)\n",
    "xgb_classifier.fit(x_train,y_train)\n",
    "train_score=xgb_classifier.score(x_train,y_train)\n",
    "test_score=xgb_classifier.score(x_test,y_test)\n",
    "print(f\"Train Accuracy = {train_score}\\nTest Accuracy = {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[100   3]\n",
      " [ 48  49]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=xgb_classifier.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80       103\n",
      "           1       0.94      0.51      0.66        97\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.81      0.74      0.73       200\n",
      "weighted avg       0.80      0.74      0.73       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine models for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 0.97375\n",
      "Test Accuracy = 0.78\n"
     ]
    }
   ],
   "source": [
    "SVC = SVC(kernel='linear')\n",
    "SVC.fit(x_train,y_train)\n",
    "train_score=SVC.score(x_train,y_train)\n",
    "test_score=SVC.score(x_test,y_test)\n",
    "print(f\"Train Accuracy = {train_score}\\nTest Accuracy = {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[84 19]\n",
      " [25 72]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=SVC.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79       103\n",
      "           1       0.79      0.74      0.77        97\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.78      0.78      0.78       200\n",
      "weighted avg       0.78      0.78      0.78       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
